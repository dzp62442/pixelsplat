# @package _global_

defaults:
  - override /dataset: omniscene
  - override /model/encoder: epipolar
  - override /model/decoder: splatting_cuda
  - override /loss: [mse, lpips]

wandb:
  name: omniscene_112x200
  tags: [omniscene, 112x200]

dataset:
  image_shape: [112, 200]

data_loader:
  train:
    batch_size: 1
  val:
    batch_size: 1
  test:
    batch_size: 1

trainer:
  max_steps: 100_001
  val_check_interval: 0.01

loss:
  lpips:
    weight: 0.05
    apply_after_step: 0
